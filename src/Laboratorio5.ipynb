{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgJm8eDEqmymdD07HlY24/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinChenWu/IE-0624-Laboratorio-5/blob/main/src/Laboratorio5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratorio 5\n",
        "\n",
        "Estudiante: Kevin Chen Wu<br/>\n",
        "Carné: B92215<br/><br/>\n",
        "Este es el Jupyter Notebook creado en Google Colab para realizar la construcción y entrenamiento del modelo HAR (Human Activity Recognition, en inglés) mediante TensorFlow para la placa Arduino Nano 33 BLE Sense."
      ],
      "metadata": {
        "id": "jLyfqIDeLVTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup del ambiente de ejecución (Python)\n",
        "\n",
        "Se instala las bibliotecas y dependencias necesarias para el notebook, es necesario ejecutarlo."
      ],
      "metadata": {
        "id": "scYyQkIQNDsb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGSeM28eLSf6",
        "outputId": "12173fc6-86d5-4a24-92d3-f9b7b4907b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.22.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.11.0 in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.51.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (15.0.6.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (4.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (2.11.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (2.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.22.4)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (0.31.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (23.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (3.19.6)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (23.1.21)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (2.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.25.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.16.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (6.0.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!apt-get -qq install xxd\n",
        "!pip install pandas numpy\n",
        "!pip install tensorflow==2.11.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datos para construcción y entrenamiento del modelo\n",
        "\n",
        "Se debe subir los archivos csv del registro de los movimientos a la carpeta \"/content\"."
      ],
      "metadata": {
        "id": "V99isYVCNqbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento de la Red neuronal"
      ],
      "metadata": {
        "id": "86o7EnLJOa-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparación de datos\n",
        "Se toma los datos de los archivos csv subidos y se convierten a un dataframe de pandas para entrenar la red neuronal.\n",
        "\n",
        "Se debe actualizar la lista \"Gesture\" con los nombres de los archivos csv."
      ],
      "metadata": {
        "id": "KyFBLvMpRpOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
        "\n",
        "# Se fija una semilla random para obtener los mismo números randoms\n",
        "# en cada ejecución de este notebook\n",
        "SEED = 1337\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# Lista de gestos\n",
        "GESTURES = [\n",
        "    \"punch\",\n",
        "    \"like\",\n",
        "    \"circle\"\n",
        "]\n",
        "\n",
        "SAMPLES_PER_GESTURE = 32\n",
        "\n",
        "NUM_GESTURES = len(GESTURES)\n",
        "\n",
        "# Se crea un matriz codificado en One-Hot para usarse en la salida\n",
        "ONE_HOT_ENCODED_GESTURES = np.eye(NUM_GESTURES)\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "# Se lee cada archivo csv file and y crea una entrada y salida\n",
        "for gesture_index in range(NUM_GESTURES):\n",
        "  gesture = GESTURES[gesture_index]\n",
        "  print(f\"Processing index {gesture_index} for gesture '{gesture}'.\")\n",
        "  \n",
        "  output = ONE_HOT_ENCODED_GESTURES[gesture_index]\n",
        "  \n",
        "  df = pd.read_csv(\"/content/\" + gesture + \".csv\")\n",
        "  \n",
        "  # Se calcula el número de gestos guardados en cada archivo\n",
        "  num_recordings = int(df.shape[0] / SAMPLES_PER_GESTURE)\n",
        "  \n",
        "  print(f\"\\tThere are {num_recordings} recordings of the {gesture} gesture.\")\n",
        "  \n",
        "  for i in range(num_recordings):\n",
        "    tensor = []\n",
        "    for j in range(SAMPLES_PER_GESTURE):\n",
        "      index = i * SAMPLES_PER_GESTURE + j\n",
        "      # Se normaliza los datos de entrada de 0 a 1:\n",
        "      # - La aceleracción está entre -4 a +4\n",
        "      # - El giroscopio está entre -2000 a +2000\n",
        "      tensor += [\n",
        "          (df['gX'][index] + 2000) / 4000,\n",
        "          (df['gY'][index] + 2000) / 4000,\n",
        "          (df['gZ'][index] + 2000) / 4000\n",
        "      ]\n",
        "\n",
        "    inputs.append(tensor)\n",
        "    outputs.append(output)\n",
        "\n",
        "# Se convierte la lista a un arreglo de numpy\n",
        "inputs = np.array(inputs)\n",
        "outputs = np.array(outputs)\n",
        "\n",
        "print(\"Data set parsing and preparation complete.\")"
      ],
      "metadata": {
        "id": "GldJs9OHCrwb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "345cb815-4f6f-4a76-bcbc-e997aafc6e7d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version = 2.11.0\n",
            "\n",
            "Processing index 0 for gesture 'punch'.\n",
            "\tThere are 32 recordings of the punch gesture.\n",
            "Processing index 1 for gesture 'like'.\n",
            "\tThere are 32 recordings of the like gesture.\n",
            "Processing index 2 for gesture 'circle'.\n",
            "\tThere are 32 recordings of the circle gesture.\n",
            "Data set parsing and preparation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aleatorización y división de pares de entradas y salidas para entrenamiento\n",
        "\n",
        "Aleatoriamente se divide los pares de entradas y salidas en conjuntos de datos: 60% para entrenamiento, 20% para validación y 20% para pruebas."
      ],
      "metadata": {
        "id": "0afBsOAuJEZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se aleatoriza el orden de las entradas para distribuirlos equitativamente\n",
        "# en entrenamiento, validación y pruebas\n",
        "# https://stackoverflow.com/a/37710486/2020087\n",
        "num_inputs = len(inputs)\n",
        "randomize = np.arange(num_inputs)\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Se intercambia los índices consecutivos (0, 1, 2, etc) con índices randoms\n",
        "inputs = inputs[randomize]\n",
        "outputs = outputs[randomize]\n",
        "\n",
        "# Se divide los datos en 3 conjuntos: entrenamiento, validación y pruebas\n",
        "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
        "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
        "\n",
        "inputs_train, inputs_test, \\\n",
        "inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "outputs_train, outputs_test, \\\n",
        "outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "print(\"Data set randomization and splitting complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImlGls9BJ_04",
        "outputId": "81bae823-8b1b-4521-a99e-d265b59ee285"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data set randomization and splitting complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construcción y entrenamiento del modelo\n",
        "\n",
        "Se construye y se entrena un modelo [TensorFlow](https://www.tensorflow.org) usando API de alto nivel [Keras](https://www.tensorflow.org/guide/keras)."
      ],
      "metadata": {
        "id": "Uu5jpCQxMIV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se construye el modelo y se entrena\n",
        "model = tf.keras.Sequential()\n",
        "# Se usa ReLu como función de activación\n",
        "model.add(tf.keras.layers.Dense(50, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(15, activation=\"relu\"))\n",
        "# Se usa softmax para la capa de salida (se asume un gesto a la vez)\n",
        "model.add(tf.keras.layers.Dense(NUM_GESTURES, activation='softmax'))\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
        "history = model.fit(\n",
        "    inputs_train, outputs_train, \n",
        "    epochs=600, batch_size=1, \n",
        "    validation_data=(inputs_validate, outputs_validate)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrsefkYBMg30",
        "outputId": "d6edf02d-1b14-43fe-e2fb-421c93644d1a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "57/57 [==============================] - 2s 8ms/step - loss: 0.2252 - mae: 0.4447 - val_loss: 0.2396 - val_mae: 0.4587\n",
            "Epoch 2/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2242 - mae: 0.4430 - val_loss: 0.2375 - val_mae: 0.4565\n",
            "Epoch 3/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2245 - mae: 0.4425 - val_loss: 0.2268 - val_mae: 0.4485\n",
            "Epoch 4/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2234 - mae: 0.4446 - val_loss: 0.2292 - val_mae: 0.4507\n",
            "Epoch 5/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2254 - mae: 0.4442 - val_loss: 0.2410 - val_mae: 0.4601\n",
            "Epoch 6/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2242 - mae: 0.4441 - val_loss: 0.2474 - val_mae: 0.4641\n",
            "Epoch 7/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2237 - mae: 0.4412 - val_loss: 0.2345 - val_mae: 0.4546\n",
            "Epoch 8/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2218 - mae: 0.4417 - val_loss: 0.2465 - val_mae: 0.4627\n",
            "Epoch 9/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2225 - mae: 0.4398 - val_loss: 0.2323 - val_mae: 0.4529\n",
            "Epoch 10/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2217 - mae: 0.4411 - val_loss: 0.2384 - val_mae: 0.4578\n",
            "Epoch 11/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2210 - mae: 0.4414 - val_loss: 0.2344 - val_mae: 0.4544\n",
            "Epoch 12/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2192 - mae: 0.4374 - val_loss: 0.2260 - val_mae: 0.4448\n",
            "Epoch 13/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2166 - mae: 0.4350 - val_loss: 0.2584 - val_mae: 0.4690\n",
            "Epoch 14/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2175 - mae: 0.4340 - val_loss: 0.2189 - val_mae: 0.4388\n",
            "Epoch 15/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2209 - mae: 0.4385 - val_loss: 0.2245 - val_mae: 0.4450\n",
            "Epoch 16/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2144 - mae: 0.4336 - val_loss: 0.2423 - val_mae: 0.4578\n",
            "Epoch 17/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2141 - mae: 0.4311 - val_loss: 0.2289 - val_mae: 0.4464\n",
            "Epoch 18/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.2135 - mae: 0.4318 - val_loss: 0.2287 - val_mae: 0.4465\n",
            "Epoch 19/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2054 - mae: 0.4224 - val_loss: 0.2607 - val_mae: 0.4672\n",
            "Epoch 20/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2111 - mae: 0.4258 - val_loss: 0.1980 - val_mae: 0.4181\n",
            "Epoch 21/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2025 - mae: 0.4191 - val_loss: 0.2106 - val_mae: 0.4309\n",
            "Epoch 22/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2031 - mae: 0.4179 - val_loss: 0.1873 - val_mae: 0.4053\n",
            "Epoch 23/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.2010 - mae: 0.4179 - val_loss: 0.1846 - val_mae: 0.4032\n",
            "Epoch 24/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1969 - mae: 0.4120 - val_loss: 0.1812 - val_mae: 0.3958\n",
            "Epoch 25/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1933 - mae: 0.4096 - val_loss: 0.2169 - val_mae: 0.4308\n",
            "Epoch 26/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1876 - mae: 0.3994 - val_loss: 0.1759 - val_mae: 0.3929\n",
            "Epoch 27/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1849 - mae: 0.3987 - val_loss: 0.1630 - val_mae: 0.3728\n",
            "Epoch 28/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1800 - mae: 0.3905 - val_loss: 0.1625 - val_mae: 0.3761\n",
            "Epoch 29/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1756 - mae: 0.3863 - val_loss: 0.1538 - val_mae: 0.3574\n",
            "Epoch 30/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1693 - mae: 0.3774 - val_loss: 0.1498 - val_mae: 0.3482\n",
            "Epoch 31/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1642 - mae: 0.3679 - val_loss: 0.1453 - val_mae: 0.3488\n",
            "Epoch 32/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1583 - mae: 0.3611 - val_loss: 0.1338 - val_mae: 0.3340\n",
            "Epoch 33/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1529 - mae: 0.3528 - val_loss: 0.1602 - val_mae: 0.3626\n",
            "Epoch 34/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1479 - mae: 0.3444 - val_loss: 0.1325 - val_mae: 0.3270\n",
            "Epoch 35/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1400 - mae: 0.3317 - val_loss: 0.1191 - val_mae: 0.3034\n",
            "Epoch 36/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1362 - mae: 0.3269 - val_loss: 0.1307 - val_mae: 0.3162\n",
            "Epoch 37/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.1304 - mae: 0.3153 - val_loss: 0.1504 - val_mae: 0.3389\n",
            "Epoch 38/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.1241 - mae: 0.3027 - val_loss: 0.1126 - val_mae: 0.2815\n",
            "Epoch 39/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.1241 - mae: 0.3087 - val_loss: 0.0961 - val_mae: 0.2693\n",
            "Epoch 40/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.1144 - mae: 0.2898 - val_loss: 0.0950 - val_mae: 0.2606\n",
            "Epoch 41/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.1121 - mae: 0.2880 - val_loss: 0.1089 - val_mae: 0.2665\n",
            "Epoch 42/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.1076 - mae: 0.2762 - val_loss: 0.1012 - val_mae: 0.2649\n",
            "Epoch 43/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.1068 - mae: 0.2771 - val_loss: 0.0824 - val_mae: 0.2339\n",
            "Epoch 44/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0998 - mae: 0.2651 - val_loss: 0.0730 - val_mae: 0.2258\n",
            "Epoch 45/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.0979 - mae: 0.2588 - val_loss: 0.0680 - val_mae: 0.2173\n",
            "Epoch 46/600\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.0913 - mae: 0.2476 - val_loss: 0.0683 - val_mae: 0.2133\n",
            "Epoch 47/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0850 - mae: 0.2372 - val_loss: 0.0632 - val_mae: 0.2129\n",
            "Epoch 48/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0836 - mae: 0.2335 - val_loss: 0.0560 - val_mae: 0.1984\n",
            "Epoch 49/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0820 - mae: 0.2296 - val_loss: 0.0534 - val_mae: 0.1935\n",
            "Epoch 50/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0742 - mae: 0.2201 - val_loss: 0.1096 - val_mae: 0.2431\n",
            "Epoch 51/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0764 - mae: 0.2159 - val_loss: 0.0613 - val_mae: 0.1972\n",
            "Epoch 52/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0716 - mae: 0.2112 - val_loss: 0.0935 - val_mae: 0.2121\n",
            "Epoch 53/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0687 - mae: 0.2054 - val_loss: 0.0418 - val_mae: 0.1667\n",
            "Epoch 54/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0614 - mae: 0.1959 - val_loss: 0.0391 - val_mae: 0.1586\n",
            "Epoch 55/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0619 - mae: 0.1952 - val_loss: 0.0391 - val_mae: 0.1546\n",
            "Epoch 56/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0610 - mae: 0.1870 - val_loss: 0.0349 - val_mae: 0.1517\n",
            "Epoch 57/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0530 - mae: 0.1784 - val_loss: 0.0424 - val_mae: 0.1580\n",
            "Epoch 58/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0509 - mae: 0.1719 - val_loss: 0.0434 - val_mae: 0.1538\n",
            "Epoch 59/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0465 - mae: 0.1631 - val_loss: 0.0313 - val_mae: 0.1357\n",
            "Epoch 60/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0471 - mae: 0.1650 - val_loss: 0.0902 - val_mae: 0.2123\n",
            "Epoch 61/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0478 - mae: 0.1679 - val_loss: 0.0379 - val_mae: 0.1444\n",
            "Epoch 62/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0437 - mae: 0.1517 - val_loss: 0.0300 - val_mae: 0.1252\n",
            "Epoch 63/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0400 - mae: 0.1494 - val_loss: 0.0429 - val_mae: 0.1446\n",
            "Epoch 64/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0384 - mae: 0.1459 - val_loss: 0.0290 - val_mae: 0.1246\n",
            "Epoch 65/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0374 - mae: 0.1420 - val_loss: 0.0203 - val_mae: 0.1067\n",
            "Epoch 66/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0351 - mae: 0.1348 - val_loss: 0.0596 - val_mae: 0.1680\n",
            "Epoch 67/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0342 - mae: 0.1362 - val_loss: 0.0513 - val_mae: 0.1491\n",
            "Epoch 68/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0343 - mae: 0.1305 - val_loss: 0.0517 - val_mae: 0.1534\n",
            "Epoch 69/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0300 - mae: 0.1252 - val_loss: 0.0200 - val_mae: 0.1006\n",
            "Epoch 70/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 0.1138 - val_loss: 0.0120 - val_mae: 0.0834\n",
            "Epoch 71/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0277 - mae: 0.1197 - val_loss: 0.0168 - val_mae: 0.0899\n",
            "Epoch 72/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0245 - mae: 0.1053 - val_loss: 0.0206 - val_mae: 0.0977\n",
            "Epoch 73/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0263 - mae: 0.1088 - val_loss: 0.0113 - val_mae: 0.0756\n",
            "Epoch 74/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0220 - mae: 0.1056 - val_loss: 0.0116 - val_mae: 0.0791\n",
            "Epoch 75/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0247 - mae: 0.1080 - val_loss: 0.0085 - val_mae: 0.0699\n",
            "Epoch 76/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0225 - mae: 0.0978 - val_loss: 0.0103 - val_mae: 0.0747\n",
            "Epoch 77/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0203 - mae: 0.0956 - val_loss: 0.0106 - val_mae: 0.0726\n",
            "Epoch 78/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0216 - mae: 0.0937 - val_loss: 0.0073 - val_mae: 0.0637\n",
            "Epoch 79/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0134 - mae: 0.0823 - val_loss: 0.0064 - val_mae: 0.0607\n",
            "Epoch 80/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0180 - mae: 0.0844 - val_loss: 0.0082 - val_mae: 0.0618\n",
            "Epoch 81/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0152 - mae: 0.0780 - val_loss: 0.0580 - val_mae: 0.1521\n",
            "Epoch 82/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0168 - mae: 0.0826 - val_loss: 0.0142 - val_mae: 0.0793\n",
            "Epoch 83/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0151 - mae: 0.0791 - val_loss: 0.0088 - val_mae: 0.0627\n",
            "Epoch 84/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0217 - mae: 0.0873 - val_loss: 0.0056 - val_mae: 0.0532\n",
            "Epoch 85/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0117 - mae: 0.0712 - val_loss: 0.0041 - val_mae: 0.0472\n",
            "Epoch 86/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0114 - mae: 0.0690 - val_loss: 0.0058 - val_mae: 0.0530\n",
            "Epoch 87/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0604 - val_loss: 0.0086 - val_mae: 0.0597\n",
            "Epoch 88/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0151 - mae: 0.0676 - val_loss: 0.0040 - val_mae: 0.0434\n",
            "Epoch 89/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0119 - mae: 0.0656 - val_loss: 0.0032 - val_mae: 0.0418\n",
            "Epoch 90/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0118 - mae: 0.0593 - val_loss: 0.0117 - val_mae: 0.0691\n",
            "Epoch 91/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0124 - mae: 0.0618 - val_loss: 0.0056 - val_mae: 0.0510\n",
            "Epoch 92/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.0584 - val_loss: 0.0033 - val_mae: 0.0416\n",
            "Epoch 93/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0558 - val_loss: 0.0027 - val_mae: 0.0367\n",
            "Epoch 94/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0521 - val_loss: 0.0271 - val_mae: 0.0997\n",
            "Epoch 95/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0108 - mae: 0.0528 - val_loss: 0.0580 - val_mae: 0.1458\n",
            "Epoch 96/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 0.0604 - val_loss: 0.0218 - val_mae: 0.0861\n",
            "Epoch 97/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.0555 - val_loss: 0.0021 - val_mae: 0.0329\n",
            "Epoch 98/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0069 - mae: 0.0453 - val_loss: 0.0018 - val_mae: 0.0303\n",
            "Epoch 99/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0445 - val_loss: 0.0226 - val_mae: 0.0902\n",
            "Epoch 100/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0455 - val_loss: 0.0020 - val_mae: 0.0300\n",
            "Epoch 101/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0470 - val_loss: 0.0028 - val_mae: 0.0361\n",
            "Epoch 102/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0078 - mae: 0.0449 - val_loss: 0.0206 - val_mae: 0.0785\n",
            "Epoch 103/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0079 - mae: 0.0424 - val_loss: 0.0640 - val_mae: 0.1491\n",
            "Epoch 104/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0051 - mae: 0.0400 - val_loss: 0.0039 - val_mae: 0.0397\n",
            "Epoch 105/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0059 - mae: 0.0387 - val_loss: 0.0011 - val_mae: 0.0242\n",
            "Epoch 106/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0060 - mae: 0.0372 - val_loss: 0.0013 - val_mae: 0.0240\n",
            "Epoch 107/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0394 - val_loss: 0.0013 - val_mae: 0.0253\n",
            "Epoch 108/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0083 - mae: 0.0412 - val_loss: 0.0028 - val_mae: 0.0320\n",
            "Epoch 109/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0032 - mae: 0.0326 - val_loss: 0.0049 - val_mae: 0.0425\n",
            "Epoch 110/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0391 - val_loss: 8.9082e-04 - val_mae: 0.0207\n",
            "Epoch 111/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0061 - mae: 0.0365 - val_loss: 0.0031 - val_mae: 0.0339\n",
            "Epoch 112/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0088 - mae: 0.0405 - val_loss: 8.2916e-04 - val_mae: 0.0200\n",
            "Epoch 113/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0252 - val_loss: 0.0080 - val_mae: 0.0465\n",
            "Epoch 114/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0106 - mae: 0.0451 - val_loss: 8.3355e-04 - val_mae: 0.0199\n",
            "Epoch 115/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0358 - val_loss: 7.6450e-04 - val_mae: 0.0188\n",
            "Epoch 116/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0033 - mae: 0.0249 - val_loss: 0.0179 - val_mae: 0.0659\n",
            "Epoch 117/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0056 - mae: 0.0295 - val_loss: 6.7687e-04 - val_mae: 0.0168\n",
            "Epoch 118/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0029 - mae: 0.0293 - val_loss: 7.3906e-04 - val_mae: 0.0167\n",
            "Epoch 119/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0055 - mae: 0.0281 - val_loss: 5.4084e-04 - val_mae: 0.0155\n",
            "Epoch 120/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0048 - mae: 0.0285 - val_loss: 7.5546e-04 - val_mae: 0.0173\n",
            "Epoch 121/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0344 - val_loss: 0.0011 - val_mae: 0.0177\n",
            "Epoch 122/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0220 - val_loss: 6.3178e-04 - val_mae: 0.0155\n",
            "Epoch 123/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0048 - mae: 0.0271 - val_loss: 4.4582e-04 - val_mae: 0.0141\n",
            "Epoch 124/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0112 - mae: 0.0403 - val_loss: 4.7668e-04 - val_mae: 0.0152\n",
            "Epoch 125/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0054 - mae: 0.0269 - val_loss: 5.7058e-04 - val_mae: 0.0162\n",
            "Epoch 126/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0011 - mae: 0.0188 - val_loss: 0.0017 - val_mae: 0.0252\n",
            "Epoch 127/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0065 - mae: 0.0256 - val_loss: 0.0074 - val_mae: 0.0489\n",
            "Epoch 128/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0068 - mae: 0.0275 - val_loss: 4.4595e-04 - val_mae: 0.0142\n",
            "Epoch 129/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0253 - val_loss: 3.1354e-04 - val_mae: 0.0125\n",
            "Epoch 130/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0198 - val_loss: 7.2218e-04 - val_mae: 0.0160\n",
            "Epoch 131/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0271 - val_loss: 3.1179e-04 - val_mae: 0.0122\n",
            "Epoch 132/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0010 - mae: 0.0188 - val_loss: 0.0015 - val_mae: 0.0229\n",
            "Epoch 133/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0044 - mae: 0.0284 - val_loss: 5.8117e-04 - val_mae: 0.0149\n",
            "Epoch 134/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0071 - mae: 0.0231 - val_loss: 3.0786e-04 - val_mae: 0.0115\n",
            "Epoch 135/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0197 - val_loss: 2.7814e-04 - val_mae: 0.0109\n",
            "Epoch 136/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0038 - mae: 0.0194 - val_loss: 9.9272e-04 - val_mae: 0.0143\n",
            "Epoch 137/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0073 - mae: 0.0216 - val_loss: 2.6948e-04 - val_mae: 0.0113\n",
            "Epoch 138/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0072 - mae: 0.0217 - val_loss: 2.0504e-04 - val_mae: 0.0099\n",
            "Epoch 139/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0067 - mae: 0.0227 - val_loss: 5.6779e-04 - val_mae: 0.0136\n",
            "Epoch 140/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0209 - val_loss: 2.3594e-04 - val_mae: 0.0100\n",
            "Epoch 141/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0183 - val_loss: 3.1329e-04 - val_mae: 0.0110\n",
            "Epoch 142/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0260 - val_loss: 1.8847e-04 - val_mae: 0.0096\n",
            "Epoch 143/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0207 - val_loss: 2.5739e-04 - val_mae: 0.0104\n",
            "Epoch 144/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0055 - mae: 0.0198 - val_loss: 3.5266e-04 - val_mae: 0.0114\n",
            "Epoch 145/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0064 - mae: 0.0290 - val_loss: 2.4363e-04 - val_mae: 0.0103\n",
            "Epoch 146/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.0014 - mae: 0.0148 - val_loss: 6.4431e-04 - val_mae: 0.0136\n",
            "Epoch 147/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0200 - val_loss: 2.2336e-04 - val_mae: 0.0095\n",
            "Epoch 148/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 4.4190e-04 - mae: 0.0114 - val_loss: 7.5213e-04 - val_mae: 0.0136\n",
            "Epoch 149/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.0134 - mae: 0.0299 - val_loss: 1.3281e-04 - val_mae: 0.0080\n",
            "Epoch 150/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0027 - mae: 0.0153 - val_loss: 2.0034e-04 - val_mae: 0.0085\n",
            "Epoch 151/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0248 - val_loss: 2.0254e-04 - val_mae: 0.0092\n",
            "Epoch 152/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0188 - val_loss: 1.4933e-04 - val_mae: 0.0083\n",
            "Epoch 153/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 9.8004e-04 - mae: 0.0130 - val_loss: 1.6409e-04 - val_mae: 0.0084\n",
            "Epoch 154/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0183 - val_loss: 1.2858e-04 - val_mae: 0.0078\n",
            "Epoch 155/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0021 - mae: 0.0162 - val_loss: 1.6530e-04 - val_mae: 0.0083\n",
            "Epoch 156/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0030 - mae: 0.0146 - val_loss: 2.7137e-04 - val_mae: 0.0094\n",
            "Epoch 157/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0124 - val_loss: 3.9614e-04 - val_mae: 0.0106\n",
            "Epoch 158/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0161 - val_loss: 2.3733e-04 - val_mae: 0.0085\n",
            "Epoch 159/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0041 - mae: 0.0197 - val_loss: 5.4485e-04 - val_mae: 0.0135\n",
            "Epoch 160/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.7136e-04 - mae: 0.0125 - val_loss: 5.0528e-04 - val_mae: 0.0113\n",
            "Epoch 161/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0031 - mae: 0.0150 - val_loss: 1.0306e-04 - val_mae: 0.0066\n",
            "Epoch 162/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0120 - val_loss: 9.9981e-05 - val_mae: 0.0068\n",
            "Epoch 163/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0035 - mae: 0.0182 - val_loss: 8.7397e-05 - val_mae: 0.0065\n",
            "Epoch 164/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0026 - mae: 0.0166 - val_loss: 0.0015 - val_mae: 0.0148\n",
            "Epoch 165/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.2686e-04 - mae: 0.0106 - val_loss: 9.1602e-05 - val_mae: 0.0066\n",
            "Epoch 166/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0070 - mae: 0.0190 - val_loss: 9.1927e-05 - val_mae: 0.0063\n",
            "Epoch 167/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.1624e-04 - mae: 0.0082 - val_loss: 3.4865e-04 - val_mae: 0.0082\n",
            "Epoch 168/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0038 - mae: 0.0168 - val_loss: 7.2725e-04 - val_mae: 0.0154\n",
            "Epoch 169/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0010 - mae: 0.0140 - val_loss: 7.8262e-05 - val_mae: 0.0061\n",
            "Epoch 170/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0010 - mae: 0.0133 - val_loss: 1.6583e-04 - val_mae: 0.0082\n",
            "Epoch 171/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0201 - val_loss: 3.4253e-04 - val_mae: 0.0097\n",
            "Epoch 172/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.8058e-04 - mae: 0.0096 - val_loss: 0.0015 - val_mae: 0.0214\n",
            "Epoch 173/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0062 - mae: 0.0161 - val_loss: 7.0254e-05 - val_mae: 0.0057\n",
            "Epoch 174/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 3.3459e-04 - mae: 0.0084 - val_loss: 2.1507e-04 - val_mae: 0.0071\n",
            "Epoch 175/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0018 - mae: 0.0158 - val_loss: 6.0580e-05 - val_mae: 0.0056\n",
            "Epoch 176/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0060 - mae: 0.0146 - val_loss: 6.4703e-05 - val_mae: 0.0055\n",
            "Epoch 177/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.2654e-04 - mae: 0.0114 - val_loss: 8.7248e-05 - val_mae: 0.0058\n",
            "Epoch 178/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0027 - mae: 0.0159 - val_loss: 5.3857e-05 - val_mae: 0.0052\n",
            "Epoch 179/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.0289e-04 - mae: 0.0061 - val_loss: 6.8567e-05 - val_mae: 0.0054\n",
            "Epoch 180/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0017 - mae: 0.0135 - val_loss: 1.1202e-04 - val_mae: 0.0068\n",
            "Epoch 181/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0122 - val_loss: 1.3694e-04 - val_mae: 0.0072\n",
            "Epoch 182/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0122 - val_loss: 5.0366e-05 - val_mae: 0.0049\n",
            "Epoch 183/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0140 - val_loss: 2.7643e-04 - val_mae: 0.0095\n",
            "Epoch 184/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7959e-04 - mae: 0.0066 - val_loss: 9.7037e-05 - val_mae: 0.0058\n",
            "Epoch 185/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0136 - val_loss: 5.3337e-05 - val_mae: 0.0050\n",
            "Epoch 186/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0063 - mae: 0.0164 - val_loss: 5.1849e-04 - val_mae: 0.0122\n",
            "Epoch 187/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.0837e-04 - mae: 0.0072 - val_loss: 6.0151e-05 - val_mae: 0.0053\n",
            "Epoch 188/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0011 - mae: 0.0104 - val_loss: 6.4660e-05 - val_mae: 0.0050\n",
            "Epoch 189/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0126 - val_loss: 1.4225e-04 - val_mae: 0.0073\n",
            "Epoch 190/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.8293e-04 - mae: 0.0063 - val_loss: 4.9537e-05 - val_mae: 0.0045\n",
            "Epoch 191/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0045 - mae: 0.0164 - val_loss: 5.2525e-05 - val_mae: 0.0050\n",
            "Epoch 192/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0075 - mae: 0.0176 - val_loss: 2.1336e-04 - val_mae: 0.0076\n",
            "Epoch 193/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 8.6198e-05 - mae: 0.0060 - val_loss: 4.0425e-05 - val_mae: 0.0045\n",
            "Epoch 194/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.4368e-04 - mae: 0.0106 - val_loss: 0.0013 - val_mae: 0.0183\n",
            "Epoch 195/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.4751e-05 - mae: 0.0056 - val_loss: 6.5120e-05 - val_mae: 0.0047\n",
            "Epoch 196/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0159 - val_loss: 3.7878e-05 - val_mae: 0.0043\n",
            "Epoch 197/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0112 - val_loss: 1.3595e-04 - val_mae: 0.0062\n",
            "Epoch 198/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0092 - val_loss: 1.7912e-04 - val_mae: 0.0074\n",
            "Epoch 199/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0138 - val_loss: 4.1816e-05 - val_mae: 0.0043\n",
            "Epoch 200/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0086 - mae: 0.0154 - val_loss: 1.1513e-04 - val_mae: 0.0061\n",
            "Epoch 201/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 1.1920e-04 - mae: 0.0058 - val_loss: 4.0085e-05 - val_mae: 0.0042\n",
            "Epoch 202/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 7.9381e-04 - mae: 0.0094 - val_loss: 5.1912e-05 - val_mae: 0.0043\n",
            "Epoch 203/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0133 - val_loss: 2.8834e-05 - val_mae: 0.0037\n",
            "Epoch 204/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 8.9473e-05 - mae: 0.0048 - val_loss: 7.2198e-05 - val_mae: 0.0045\n",
            "Epoch 205/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0011 - mae: 0.0105 - val_loss: 4.3731e-05 - val_mae: 0.0044\n",
            "Epoch 206/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 7.9251e-05 - mae: 0.0051 - val_loss: 2.8556e-05 - val_mae: 0.0037\n",
            "Epoch 207/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0115 - val_loss: 2.9368e-05 - val_mae: 0.0035\n",
            "Epoch 208/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0027 - mae: 0.0100 - val_loss: 5.5214e-05 - val_mae: 0.0045\n",
            "Epoch 209/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 5.1245e-04 - mae: 0.0082 - val_loss: 2.9310e-05 - val_mae: 0.0035\n",
            "Epoch 210/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0028 - mae: 0.0112 - val_loss: 2.9754e-05 - val_mae: 0.0037\n",
            "Epoch 211/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0061 - mae: 0.0128 - val_loss: 2.7143e-05 - val_mae: 0.0035\n",
            "Epoch 212/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.6931e-04 - mae: 0.0057 - val_loss: 2.8582e-05 - val_mae: 0.0035\n",
            "Epoch 213/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0043 - mae: 0.0110 - val_loss: 4.3113e-04 - val_mae: 0.0077\n",
            "Epoch 214/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.0698e-05 - mae: 0.0049 - val_loss: 2.4166e-05 - val_mae: 0.0032\n",
            "Epoch 215/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0076 - mae: 0.0175 - val_loss: 3.1735e-05 - val_mae: 0.0035\n",
            "Epoch 216/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.6980e-05 - mae: 0.0038 - val_loss: 3.4271e-05 - val_mae: 0.0035\n",
            "Epoch 217/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0057 - mae: 0.0138 - val_loss: 0.0015 - val_mae: 0.0118\n",
            "Epoch 218/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5552e-04 - mae: 0.0054 - val_loss: 2.8242e-05 - val_mae: 0.0032\n",
            "Epoch 219/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0124 - val_loss: 1.9469e-04 - val_mae: 0.0054\n",
            "Epoch 220/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0126 - val_loss: 3.2193e-05 - val_mae: 0.0036\n",
            "Epoch 221/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0028 - mae: 0.0104 - val_loss: 8.5900e-05 - val_mae: 0.0050\n",
            "Epoch 222/600\n",
            "57/57 [==============================] - 1s 13ms/step - loss: 7.9764e-04 - mae: 0.0084 - val_loss: 2.0881e-05 - val_mae: 0.0031\n",
            "Epoch 223/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0058 - mae: 0.0118 - val_loss: 3.6844e-04 - val_mae: 0.0097\n",
            "Epoch 224/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7537e-04 - mae: 0.0061 - val_loss: 2.7695e-05 - val_mae: 0.0035\n",
            "Epoch 225/600\n",
            "57/57 [==============================] - 1s 16ms/step - loss: 8.8418e-04 - mae: 0.0088 - val_loss: 0.0138 - val_mae: 0.0377\n",
            "Epoch 226/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.5307e-04 - mae: 0.0072 - val_loss: 1.7358e-05 - val_mae: 0.0028\n",
            "Epoch 227/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0099 - val_loss: 1.6785e-05 - val_mae: 0.0028\n",
            "Epoch 228/600\n",
            "57/57 [==============================] - 1s 15ms/step - loss: 4.7296e-05 - mae: 0.0032 - val_loss: 0.1801 - val_mae: 0.2319\n",
            "Epoch 229/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0147 - val_loss: 2.6817e-05 - val_mae: 0.0032\n",
            "Epoch 230/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0014 - mae: 0.0085 - val_loss: 0.0010 - val_mae: 0.0088\n",
            "Epoch 231/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1838e-04 - mae: 0.0054 - val_loss: 2.1110e-05 - val_mae: 0.0029\n",
            "Epoch 232/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0122 - val_loss: 2.2111e-05 - val_mae: 0.0030\n",
            "Epoch 233/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0011 - mae: 0.0075 - val_loss: 7.0119e-05 - val_mae: 0.0047\n",
            "Epoch 234/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.2378e-05 - mae: 0.0040 - val_loss: 2.1770e-05 - val_mae: 0.0030\n",
            "Epoch 235/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.1153e-04 - mae: 0.0079 - val_loss: 1.4030e-05 - val_mae: 0.0026\n",
            "Epoch 236/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0063 - mae: 0.0144 - val_loss: 5.2320e-05 - val_mae: 0.0041\n",
            "Epoch 237/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0136 - val_loss: 7.7772e-04 - val_mae: 0.0083\n",
            "Epoch 238/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0012 - mae: 0.0094 - val_loss: 2.3597e-04 - val_mae: 0.0063\n",
            "Epoch 239/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.0355e-04 - mae: 0.0077 - val_loss: 5.7778e-05 - val_mae: 0.0039\n",
            "Epoch 240/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0090 - val_loss: 1.4815e-05 - val_mae: 0.0025\n",
            "Epoch 241/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0091 - val_loss: 1.5882e-05 - val_mae: 0.0024\n",
            "Epoch 242/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.5491e-05 - mae: 0.0028 - val_loss: 1.3060e-05 - val_mae: 0.0024\n",
            "Epoch 243/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0083 - val_loss: 1.8021e-05 - val_mae: 0.0027\n",
            "Epoch 244/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 1.7221e-04 - mae: 0.0046 - val_loss: 1.2605e-05 - val_mae: 0.0024\n",
            "Epoch 245/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 2.9356e-04 - mae: 0.0058 - val_loss: 1.8480e-05 - val_mae: 0.0027\n",
            "Epoch 246/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0102 - val_loss: 3.0363e-05 - val_mae: 0.0032\n",
            "Epoch 247/600\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 3.5634e-05 - mae: 0.0032 - val_loss: 1.4070e-05 - val_mae: 0.0025\n",
            "Epoch 248/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0156 - val_loss: 8.7433e-05 - val_mae: 0.0050\n",
            "Epoch 249/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 4.8219e-05 - mae: 0.0036 - val_loss: 4.9430e-05 - val_mae: 0.0032\n",
            "Epoch 250/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0112 - val_loss: 1.3855e-05 - val_mae: 0.0023\n",
            "Epoch 251/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 4.7042e-05 - mae: 0.0035 - val_loss: 0.0062 - val_mae: 0.0383\n",
            "Epoch 252/600\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 0.0029 - mae: 0.0136 - val_loss: 3.3604e-04 - val_mae: 0.0096\n",
            "Epoch 253/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 6.1360e-04 - mae: 0.0078 - val_loss: 1.3112e-05 - val_mae: 0.0024\n",
            "Epoch 254/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0089 - mae: 0.0168 - val_loss: 6.0467e-05 - val_mae: 0.0044\n",
            "Epoch 255/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.8777e-04 - mae: 0.0054 - val_loss: 1.1708e-05 - val_mae: 0.0021\n",
            "Epoch 256/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0060 - mae: 0.0107 - val_loss: 1.2764e-04 - val_mae: 0.0058\n",
            "Epoch 257/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.7462e-05 - mae: 0.0033 - val_loss: 2.1208e-05 - val_mae: 0.0024\n",
            "Epoch 258/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0026 - mae: 0.0114 - val_loss: 1.3465e-04 - val_mae: 0.0051\n",
            "Epoch 259/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.3074e-05 - mae: 0.0035 - val_loss: 2.0984e-05 - val_mae: 0.0025\n",
            "Epoch 260/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0053 - mae: 0.0106 - val_loss: 1.5761e-05 - val_mae: 0.0025\n",
            "Epoch 261/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.4711e-05 - mae: 0.0031 - val_loss: 8.9256e-06 - val_mae: 0.0020\n",
            "Epoch 262/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1473e-05 - mae: 0.0027 - val_loss: 2.0717e-05 - val_mae: 0.0022\n",
            "Epoch 263/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0119 - val_loss: 1.1263e-05 - val_mae: 0.0021\n",
            "Epoch 264/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 5.2494e-04 - mae: 0.0054 - val_loss: 2.3142e-05 - val_mae: 0.0027\n",
            "Epoch 265/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.8780e-04 - mae: 0.0057 - val_loss: 1.1202e-05 - val_mae: 0.0020\n",
            "Epoch 266/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0013 - mae: 0.0098 - val_loss: 1.5690e-05 - val_mae: 0.0022\n",
            "Epoch 267/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.2061e-05 - mae: 0.0038 - val_loss: 1.4571e-05 - val_mae: 0.0022\n",
            "Epoch 268/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0019 - mae: 0.0075 - val_loss: 1.0679e-05 - val_mae: 0.0021\n",
            "Epoch 269/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0109 - val_loss: 3.7513e-05 - val_mae: 0.0027\n",
            "Epoch 270/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3846e-05 - mae: 0.0022 - val_loss: 6.9592e-06 - val_mae: 0.0018\n",
            "Epoch 271/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 9.3089e-04 - mae: 0.0082 - val_loss: 1.2013e-04 - val_mae: 0.0055\n",
            "Epoch 272/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.5206e-05 - mae: 0.0027 - val_loss: 9.1637e-06 - val_mae: 0.0020\n",
            "Epoch 273/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0023 - mae: 0.0113 - val_loss: 4.6306e-04 - val_mae: 0.0062\n",
            "Epoch 274/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.4158e-05 - mae: 0.0040 - val_loss: 1.0958e-04 - val_mae: 0.0042\n",
            "Epoch 275/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0016 - mae: 0.0083 - val_loss: 1.1247e-05 - val_mae: 0.0021\n",
            "Epoch 276/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4189e-04 - mae: 0.0035 - val_loss: 9.4011e-06 - val_mae: 0.0019\n",
            "Epoch 277/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0051 - mae: 0.0119 - val_loss: 5.8266e-05 - val_mae: 0.0032\n",
            "Epoch 278/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.9896e-05 - mae: 0.0027 - val_loss: 1.9727e-05 - val_mae: 0.0022\n",
            "Epoch 279/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.0282e-04 - mae: 0.0056 - val_loss: 8.2356e-06 - val_mae: 0.0018\n",
            "Epoch 280/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.4108e-05 - mae: 0.0026 - val_loss: 6.0615e-06 - val_mae: 0.0017\n",
            "Epoch 281/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0047 - mae: 0.0098 - val_loss: 6.5454e-06 - val_mae: 0.0017\n",
            "Epoch 282/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.6133e-05 - mae: 0.0021 - val_loss: 7.4535e-06 - val_mae: 0.0017\n",
            "Epoch 283/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 7.0087e-04 - mae: 0.0059 - val_loss: 2.2506e-05 - val_mae: 0.0020\n",
            "Epoch 284/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.5053e-04 - mae: 0.0060 - val_loss: 6.4775e-06 - val_mae: 0.0016\n",
            "Epoch 285/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.7270e-04 - mae: 0.0073 - val_loss: 1.0607e-05 - val_mae: 0.0021\n",
            "Epoch 286/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.2924e-05 - mae: 0.0022 - val_loss: 1.0689e-04 - val_mae: 0.0039\n",
            "Epoch 287/600\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 8.4008e-04 - mae: 0.0082 - val_loss: 7.4766e-06 - val_mae: 0.0018\n",
            "Epoch 288/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 9.6248e-06 - mae: 0.0019 - val_loss: 4.7437e-05 - val_mae: 0.0036\n",
            "Epoch 289/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.6981e-04 - mae: 0.0049 - val_loss: 1.1369e-05 - val_mae: 0.0017\n",
            "Epoch 290/600\n",
            "57/57 [==============================] - 1s 10ms/step - loss: 0.0061 - mae: 0.0109 - val_loss: 6.8128e-06 - val_mae: 0.0017\n",
            "Epoch 291/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.4869e-05 - mae: 0.0025 - val_loss: 1.1347e-04 - val_mae: 0.0051\n",
            "Epoch 292/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0016 - mae: 0.0073 - val_loss: 6.9175e-05 - val_mae: 0.0044\n",
            "Epoch 293/600\n",
            "57/57 [==============================] - 1s 15ms/step - loss: 1.1848e-04 - mae: 0.0033 - val_loss: 6.0615e-06 - val_mae: 0.0016\n",
            "Epoch 294/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 8.9548e-05 - mae: 0.0033 - val_loss: 0.0466 - val_mae: 0.1137\n",
            "Epoch 295/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 8.5340e-05 - mae: 0.0030 - val_loss: 5.4522e-06 - val_mae: 0.0015\n",
            "Epoch 296/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0146 - val_loss: 2.1842e-05 - val_mae: 0.0023\n",
            "Epoch 297/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.4655e-05 - mae: 0.0021 - val_loss: 5.7255e-06 - val_mae: 0.0016\n",
            "Epoch 298/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0060 - val_loss: 6.4909e-06 - val_mae: 0.0017\n",
            "Epoch 299/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 8.8847e-04 - mae: 0.0079 - val_loss: 3.8371e-05 - val_mae: 0.0033\n",
            "Epoch 300/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 4.2092e-05 - mae: 0.0025 - val_loss: 5.5941e-06 - val_mae: 0.0016\n",
            "Epoch 301/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0018 - mae: 0.0075 - val_loss: 8.6109e-06 - val_mae: 0.0019\n",
            "Epoch 302/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.0627e-04 - mae: 0.0065 - val_loss: 1.0544e-05 - val_mae: 0.0020\n",
            "Epoch 303/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3988e-05 - mae: 0.0021 - val_loss: 5.9726e-06 - val_mae: 0.0016\n",
            "Epoch 304/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.0015 - mae: 0.0078 - val_loss: 4.7606e-06 - val_mae: 0.0015\n",
            "Epoch 305/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.6201e-06 - mae: 0.0016 - val_loss: 9.3727e-05 - val_mae: 0.0048\n",
            "Epoch 306/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.9346e-04 - mae: 0.0047 - val_loss: 2.3334e-04 - val_mae: 0.0076\n",
            "Epoch 307/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.1634e-04 - mae: 0.0054 - val_loss: 8.0235e-06 - val_mae: 0.0018\n",
            "Epoch 308/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.6507e-04 - mae: 0.0047 - val_loss: 2.9578e-05 - val_mae: 0.0027\n",
            "Epoch 309/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0048 - mae: 0.0104 - val_loss: 9.1659e-06 - val_mae: 0.0019\n",
            "Epoch 310/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 4.0083e-04 - mae: 0.0055 - val_loss: 1.9997e-05 - val_mae: 0.0024\n",
            "Epoch 311/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0021 - mae: 0.0080 - val_loss: 1.2695e-05 - val_mae: 0.0020\n",
            "Epoch 312/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0040 - mae: 0.0097 - val_loss: 1.3796e-05 - val_mae: 0.0022\n",
            "Epoch 313/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.1939e-05 - mae: 0.0029 - val_loss: 1.3940e-05 - val_mae: 0.0020\n",
            "Epoch 314/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.9902e-04 - mae: 0.0069 - val_loss: 1.5690e-05 - val_mae: 0.0022\n",
            "Epoch 315/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.3594e-05 - mae: 0.0027 - val_loss: 5.7412e-06 - val_mae: 0.0014\n",
            "Epoch 316/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 9.0646e-04 - mae: 0.0066 - val_loss: 4.7147e-06 - val_mae: 0.0014\n",
            "Epoch 317/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.1981e-05 - mae: 0.0023 - val_loss: 3.9529e-06 - val_mae: 0.0013\n",
            "Epoch 318/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0035 - mae: 0.0117 - val_loss: 1.7660e-05 - val_mae: 0.0022\n",
            "Epoch 319/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5986e-05 - mae: 0.0020 - val_loss: 9.5343e-06 - val_mae: 0.0018\n",
            "Epoch 320/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 5.3061e-04 - mae: 0.0063 - val_loss: 2.9338e-05 - val_mae: 0.0029\n",
            "Epoch 321/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.2992e-05 - mae: 0.0020 - val_loss: 0.0052 - val_mae: 0.0359\n",
            "Epoch 322/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.1095e-04 - mae: 0.0073 - val_loss: 6.1078e-06 - val_mae: 0.0014\n",
            "Epoch 323/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.5837e-05 - mae: 0.0029 - val_loss: 7.2889e-06 - val_mae: 0.0016\n",
            "Epoch 324/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.9788e-06 - mae: 0.0015 - val_loss: 4.6581e-06 - val_mae: 0.0013\n",
            "Epoch 325/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0010 - mae: 0.0075 - val_loss: 1.3625e-05 - val_mae: 0.0015\n",
            "Epoch 326/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0012 - mae: 0.0060 - val_loss: 9.2799e-06 - val_mae: 0.0018\n",
            "Epoch 327/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0078 - val_loss: 2.7526e-05 - val_mae: 0.0028\n",
            "Epoch 328/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.3947e-05 - mae: 0.0024 - val_loss: 3.6429e-06 - val_mae: 0.0012\n",
            "Epoch 329/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.9748e-04 - mae: 0.0040 - val_loss: 8.5734e-05 - val_mae: 0.0037\n",
            "Epoch 330/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0091 - val_loss: 1.5162e-05 - val_mae: 0.0021\n",
            "Epoch 331/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.6459e-05 - mae: 0.0025 - val_loss: 3.2253e-06 - val_mae: 0.0012\n",
            "Epoch 332/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 6.3774e-06 - mae: 0.0013 - val_loss: 1.8171e-05 - val_mae: 0.0017\n",
            "Epoch 333/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.6858e-04 - mae: 0.0061 - val_loss: 1.0851e-05 - val_mae: 0.0015\n",
            "Epoch 334/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.0961e-05 - mae: 0.0017 - val_loss: 1.1440e-05 - val_mae: 0.0018\n",
            "Epoch 335/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0051 - mae: 0.0145 - val_loss: 2.1441e-05 - val_mae: 0.0024\n",
            "Epoch 336/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.2657e-05 - mae: 0.0018 - val_loss: 3.3133e-06 - val_mae: 0.0012\n",
            "Epoch 337/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0071 - val_loss: 3.9243e-05 - val_mae: 0.0020\n",
            "Epoch 338/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7164e-05 - mae: 0.0019 - val_loss: 7.5190e-05 - val_mae: 0.0030\n",
            "Epoch 339/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.9125e-05 - mae: 0.0025 - val_loss: 1.9898e-05 - val_mae: 0.0016\n",
            "Epoch 340/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0036 - mae: 0.0087 - val_loss: 4.7800e-06 - val_mae: 0.0014\n",
            "Epoch 341/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0061 - mae: 0.0115 - val_loss: 3.2859e-05 - val_mae: 0.0029\n",
            "Epoch 342/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.6135e-05 - mae: 0.0025 - val_loss: 3.2678e-06 - val_mae: 0.0012\n",
            "Epoch 343/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.1096e-06 - mae: 0.0014 - val_loss: 3.5131e-06 - val_mae: 0.0011\n",
            "Epoch 344/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.0010 - mae: 0.0068 - val_loss: 1.5747e-05 - val_mae: 0.0018\n",
            "Epoch 345/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 6.6148e-06 - mae: 0.0014 - val_loss: 3.6037e-06 - val_mae: 0.0011\n",
            "Epoch 346/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.0012 - mae: 0.0084 - val_loss: 2.1385e-05 - val_mae: 0.0025\n",
            "Epoch 347/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 8.1692e-04 - mae: 0.0077 - val_loss: 4.1394e-05 - val_mae: 0.0028\n",
            "Epoch 348/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 9.6085e-06 - mae: 0.0014 - val_loss: 2.4539e-06 - val_mae: 0.0011\n",
            "Epoch 349/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 7.6456e-04 - mae: 0.0066 - val_loss: 1.9765e-05 - val_mae: 0.0019\n",
            "Epoch 350/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 6.8970e-06 - mae: 0.0014 - val_loss: 2.5340e-06 - val_mae: 0.0010\n",
            "Epoch 351/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 4.5427e-06 - mae: 0.0013 - val_loss: 4.1292e-04 - val_mae: 0.0097\n",
            "Epoch 352/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 9.3594e-04 - mae: 0.0083 - val_loss: 5.1383e-06 - val_mae: 0.0014\n",
            "Epoch 353/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.0403e-06 - mae: 0.0015 - val_loss: 0.0026 - val_mae: 0.0232\n",
            "Epoch 354/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.8120e-04 - mae: 0.0077 - val_loss: 4.0247e-06 - val_mae: 0.0012\n",
            "Epoch 355/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.4859e-05 - mae: 0.0019 - val_loss: 5.8974e-04 - val_mae: 0.0111\n",
            "Epoch 356/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 6.0456e-04 - mae: 0.0052 - val_loss: 4.4526e-06 - val_mae: 0.0014\n",
            "Epoch 357/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.7508e-06 - mae: 0.0014 - val_loss: 7.2501e-06 - val_mae: 0.0016\n",
            "Epoch 358/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0015 - mae: 0.0105 - val_loss: 3.3618e-06 - val_mae: 0.0012\n",
            "Epoch 359/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 3.5352e-06 - mae: 0.0012 - val_loss: 5.3772e-06 - val_mae: 0.0013\n",
            "Epoch 360/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.5952e-06 - mae: 0.0014 - val_loss: 1.8963e-05 - val_mae: 0.0023\n",
            "Epoch 361/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.6379e-06 - mae: 0.0012 - val_loss: 2.5487e-06 - val_mae: 0.0010\n",
            "Epoch 362/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.3356e-04 - mae: 0.0048 - val_loss: 4.1329e-06 - val_mae: 0.0012\n",
            "Epoch 363/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.8547e-04 - mae: 0.0047 - val_loss: 5.7358e-06 - val_mae: 0.0014\n",
            "Epoch 364/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.2736e-05 - mae: 0.0029 - val_loss: 3.4298e-05 - val_mae: 0.0030\n",
            "Epoch 365/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7386e-05 - mae: 0.0018 - val_loss: 7.1517e-06 - val_mae: 0.0014\n",
            "Epoch 366/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.0444e-06 - mae: 0.0011 - val_loss: 5.3426e-06 - val_mae: 0.0014\n",
            "Epoch 367/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.1203e-04 - mae: 0.0025 - val_loss: 5.1178e-06 - val_mae: 0.0013\n",
            "Epoch 368/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0073 - val_loss: 3.0731e-06 - val_mae: 0.0011\n",
            "Epoch 369/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.4224e-05 - mae: 0.0018 - val_loss: 2.9415e-06 - val_mae: 0.0011\n",
            "Epoch 370/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.0481e-05 - mae: 0.0015 - val_loss: 0.0071 - val_mae: 0.0276\n",
            "Epoch 371/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.1562e-05 - mae: 0.0023 - val_loss: 0.0816 - val_mae: 0.1421\n",
            "Epoch 372/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0020 - mae: 0.0069 - val_loss: 2.6333e-06 - val_mae: 0.0010\n",
            "Epoch 373/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.8915e-06 - mae: 0.0011 - val_loss: 1.9084e-06 - val_mae: 9.3290e-04\n",
            "Epoch 374/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.1039e-04 - mae: 0.0041 - val_loss: 4.5594e-06 - val_mae: 0.0010\n",
            "Epoch 375/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 5.8314e-05 - mae: 0.0020 - val_loss: 1.7146e-05 - val_mae: 0.0019\n",
            "Epoch 376/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0069 - mae: 0.0136 - val_loss: 9.2454e-06 - val_mae: 0.0017\n",
            "Epoch 377/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 0.0015 - mae: 0.0092 - val_loss: 5.2628e-06 - val_mae: 0.0014\n",
            "Epoch 378/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.3245e-05 - mae: 0.0022 - val_loss: 2.1162e-06 - val_mae: 8.6769e-04\n",
            "Epoch 379/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 8.5911e-05 - mae: 0.0028 - val_loss: 3.6055e-06 - val_mae: 0.0011\n",
            "Epoch 380/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.5880e-04 - mae: 0.0039 - val_loss: 1.7521e-06 - val_mae: 8.7013e-04\n",
            "Epoch 381/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.9822e-06 - mae: 0.0010 - val_loss: 1.5961e-06 - val_mae: 8.3154e-04\n",
            "Epoch 382/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.6149e-06 - mae: 9.6891e-04 - val_loss: 1.5726e-05 - val_mae: 0.0015\n",
            "Epoch 383/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.1239e-04 - mae: 0.0038 - val_loss: 8.4480e-06 - val_mae: 0.0015\n",
            "Epoch 384/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 9.5092e-04 - mae: 0.0055 - val_loss: 7.7531e-06 - val_mae: 0.0014\n",
            "Epoch 385/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1600e-04 - mae: 0.0033 - val_loss: 1.8604e-06 - val_mae: 8.3130e-04\n",
            "Epoch 386/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.7385e-06 - mae: 9.4883e-04 - val_loss: 1.6138e-06 - val_mae: 8.1343e-04\n",
            "Epoch 387/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 3.5693e-04 - mae: 0.0031 - val_loss: 8.3516e-06 - val_mae: 0.0015\n",
            "Epoch 388/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.8366e-04 - mae: 0.0055 - val_loss: 8.7848e-06 - val_mae: 0.0015\n",
            "Epoch 389/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.5752e-04 - mae: 0.0037 - val_loss: 2.1976e-06 - val_mae: 9.1210e-04\n",
            "Epoch 390/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.0385e-06 - mae: 0.0010 - val_loss: 5.2956e-06 - val_mae: 9.8735e-04\n",
            "Epoch 391/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.7187e-04 - mae: 0.0071 - val_loss: 2.2246e-05 - val_mae: 0.0015\n",
            "Epoch 392/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 5.7723e-06 - mae: 0.0011 - val_loss: 1.7406e-06 - val_mae: 8.1003e-04\n",
            "Epoch 393/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 5.9566e-06 - mae: 0.0012 - val_loss: 1.7569e-06 - val_mae: 8.2520e-04\n",
            "Epoch 394/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 2.8886e-06 - mae: 9.9036e-04 - val_loss: 1.3385e-06 - val_mae: 7.6386e-04\n",
            "Epoch 395/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 3.1664e-05 - mae: 0.0017 - val_loss: 3.3725e-06 - val_mae: 9.7525e-04\n",
            "Epoch 396/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0115 - val_loss: 2.4883e-05 - val_mae: 0.0025\n",
            "Epoch 397/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 2.4149e-05 - mae: 0.0019 - val_loss: 1.5679e-06 - val_mae: 8.0425e-04\n",
            "Epoch 398/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.1268e-06 - mae: 8.5183e-04 - val_loss: 1.5826e-06 - val_mae: 7.7173e-04\n",
            "Epoch 399/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 1.0439e-04 - mae: 0.0022 - val_loss: 6.3141e-06 - val_mae: 0.0013\n",
            "Epoch 400/600\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 2.5479e-04 - mae: 0.0033 - val_loss: 3.4465e-06 - val_mae: 0.0010\n",
            "Epoch 401/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 4.2359e-06 - mae: 9.8933e-04 - val_loss: 1.6256e-06 - val_mae: 7.6288e-04\n",
            "Epoch 402/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8725e-06 - mae: 8.2095e-04 - val_loss: 6.9206e-06 - val_mae: 0.0011\n",
            "Epoch 403/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.2540e-06 - mae: 0.0011 - val_loss: 1.9096e-06 - val_mae: 8.3650e-04\n",
            "Epoch 404/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 3.7698e-06 - mae: 9.9820e-04 - val_loss: 2.9012e-06 - val_mae: 0.0010\n",
            "Epoch 405/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0011 - mae: 0.0050 - val_loss: 3.1457e-05 - val_mae: 0.0023\n",
            "Epoch 406/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0010 - mae: 0.0057 - val_loss: 8.7980e-06 - val_mae: 0.0014\n",
            "Epoch 407/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4265e-04 - mae: 0.0030 - val_loss: 8.1651e-05 - val_mae: 0.0043\n",
            "Epoch 408/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.2473e-04 - mae: 0.0035 - val_loss: 3.0297e-05 - val_mae: 0.0027\n",
            "Epoch 409/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 3.5642e-04 - mae: 0.0039 - val_loss: 8.9152e-06 - val_mae: 0.0016\n",
            "Epoch 410/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.9659e-04 - mae: 0.0041 - val_loss: 6.7941e-06 - val_mae: 0.0013\n",
            "Epoch 411/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.4411e-04 - mae: 0.0040 - val_loss: 2.7518e-05 - val_mae: 0.0025\n",
            "Epoch 412/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.2525e-05 - mae: 0.0014 - val_loss: 1.2727e-06 - val_mae: 7.2342e-04\n",
            "Epoch 413/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.7846e-06 - mae: 8.8104e-04 - val_loss: 1.8959e-06 - val_mae: 7.8078e-04\n",
            "Epoch 414/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.6619e-06 - mae: 0.0011 - val_loss: 2.5046e-06 - val_mae: 8.2133e-04\n",
            "Epoch 415/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 4.1667e-06 - mae: 0.0010 - val_loss: 1.0339e-05 - val_mae: 0.0012\n",
            "Epoch 416/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7741e-06 - mae: 7.9526e-04 - val_loss: 1.1701e-06 - val_mae: 6.9943e-04\n",
            "Epoch 417/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0048 - mae: 0.0108 - val_loss: 3.3358e-05 - val_mae: 0.0024\n",
            "Epoch 418/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.2889e-05 - mae: 0.0014 - val_loss: 2.9352e-06 - val_mae: 8.5777e-04\n",
            "Epoch 419/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8948e-06 - mae: 7.7695e-04 - val_loss: 1.8250e-06 - val_mae: 7.2356e-04\n",
            "Epoch 420/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1319e-06 - mae: 8.3459e-04 - val_loss: 1.1362e-06 - val_mae: 6.5923e-04\n",
            "Epoch 421/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8027e-06 - mae: 7.6050e-04 - val_loss: 7.0500e-06 - val_mae: 0.0011\n",
            "Epoch 422/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9242e-06 - mae: 7.8427e-04 - val_loss: 1.0166e-06 - val_mae: 6.5005e-04\n",
            "Epoch 423/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.0103e-04 - mae: 0.0037 - val_loss: 4.2328e-06 - val_mae: 8.2690e-04\n",
            "Epoch 424/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.3624e-06 - mae: 8.1175e-04 - val_loss: 1.9388e-06 - val_mae: 6.9740e-04\n",
            "Epoch 425/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.9866e-06 - mae: 8.7810e-04 - val_loss: 4.3751e-06 - val_mae: 8.5035e-04\n",
            "Epoch 426/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 8.8867e-04 - mae: 0.0044 - val_loss: 4.1590e-06 - val_mae: 0.0011\n",
            "Epoch 427/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0056 - mae: 0.0111 - val_loss: 9.1292e-05 - val_mae: 0.0045\n",
            "Epoch 428/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.4370e-05 - mae: 0.0024 - val_loss: 1.9604e-06 - val_mae: 8.2725e-04\n",
            "Epoch 429/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.2223e-06 - mae: 7.5452e-04 - val_loss: 2.4838e-06 - val_mae: 7.8431e-04\n",
            "Epoch 430/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.2570e-06 - mae: 7.9908e-04 - val_loss: 2.7015e-06 - val_mae: 7.9572e-04\n",
            "Epoch 431/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.1225e-06 - mae: 7.8120e-04 - val_loss: 3.4485e-06 - val_mae: 9.1710e-04\n",
            "Epoch 432/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.3590e-06 - mae: 8.5802e-04 - val_loss: 1.0122e-06 - val_mae: 6.6073e-04\n",
            "Epoch 433/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.1781e-05 - mae: 0.0024 - val_loss: 1.0897e-05 - val_mae: 0.0014\n",
            "Epoch 434/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.3857e-06 - mae: 8.2211e-04 - val_loss: 9.2399e-07 - val_mae: 6.2022e-04\n",
            "Epoch 435/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.7011e-06 - mae: 7.4700e-04 - val_loss: 1.1773e-06 - val_mae: 6.4556e-04\n",
            "Epoch 436/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 3.5879e-06 - mae: 9.2302e-04 - val_loss: 2.2341e-06 - val_mae: 7.2338e-04\n",
            "Epoch 437/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.6174e-06 - mae: 7.3416e-04 - val_loss: 8.9574e-07 - val_mae: 6.1596e-04\n",
            "Epoch 438/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0057 - val_loss: 1.2331e-05 - val_mae: 0.0016\n",
            "Epoch 439/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 0.0016 - mae: 0.0086 - val_loss: 1.2716e-05 - val_mae: 0.0017\n",
            "Epoch 440/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.9136e-06 - mae: 0.0013 - val_loss: 9.9197e-07 - val_mae: 6.4028e-04\n",
            "Epoch 441/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 1.7407e-06 - mae: 7.4207e-04 - val_loss: 1.0424e-06 - val_mae: 6.4026e-04\n",
            "Epoch 442/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5896e-06 - mae: 7.4146e-04 - val_loss: 9.2958e-07 - val_mae: 6.2236e-04\n",
            "Epoch 443/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 1.5200e-06 - mae: 7.0497e-04 - val_loss: 5.2508e-06 - val_mae: 0.0010\n",
            "Epoch 444/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 1.5182e-06 - mae: 7.3828e-04 - val_loss: 9.9645e-07 - val_mae: 6.3276e-04\n",
            "Epoch 445/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 2.2329e-06 - mae: 7.4326e-04 - val_loss: 1.9656e-06 - val_mae: 6.6374e-04\n",
            "Epoch 446/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 5.8125e-04 - mae: 0.0045 - val_loss: 0.0014 - val_mae: 0.0076\n",
            "Epoch 447/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 7.2675e-05 - mae: 0.0025 - val_loss: 4.6933e-05 - val_mae: 0.0017\n",
            "Epoch 448/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 4.1594e-06 - mae: 9.2333e-04 - val_loss: 1.9687e-06 - val_mae: 6.4972e-04\n",
            "Epoch 449/600\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 3.9906e-06 - mae: 8.5599e-04 - val_loss: 1.9845e-06 - val_mae: 6.4686e-04\n",
            "Epoch 450/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 3.0148e-06 - mae: 8.2406e-04 - val_loss: 1.0114e-06 - val_mae: 6.2535e-04\n",
            "Epoch 451/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 6.6208e-05 - mae: 0.0017 - val_loss: 3.7675e-06 - val_mae: 0.0011\n",
            "Epoch 452/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 3.3186e-04 - mae: 0.0043 - val_loss: 1.8430e-06 - val_mae: 7.4874e-04\n",
            "Epoch 453/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 2.6582e-06 - mae: 7.7841e-04 - val_loss: 8.7633e-07 - val_mae: 5.8343e-04\n",
            "Epoch 454/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.0695e-06 - mae: 7.6022e-04 - val_loss: 9.1638e-07 - val_mae: 5.8417e-04\n",
            "Epoch 455/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.9408e-06 - mae: 7.0638e-04 - val_loss: 1.1795e-06 - val_mae: 6.0324e-04\n",
            "Epoch 456/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.6953e-07 - mae: 6.0222e-04 - val_loss: 2.0930e-06 - val_mae: 6.8481e-04\n",
            "Epoch 457/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.3912e-06 - mae: 6.6341e-04 - val_loss: 8.6733e-07 - val_mae: 5.4406e-04\n",
            "Epoch 458/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.9793e-06 - mae: 7.3124e-04 - val_loss: 2.0357e-06 - val_mae: 6.1564e-04\n",
            "Epoch 459/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3971e-06 - mae: 6.3232e-04 - val_loss: 9.8099e-06 - val_mae: 0.0010\n",
            "Epoch 460/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.8348e-06 - mae: 6.7538e-04 - val_loss: 7.7521e-06 - val_mae: 0.0011\n",
            "Epoch 461/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.5123e-06 - mae: 6.8501e-04 - val_loss: 1.1448e-06 - val_mae: 5.6406e-04\n",
            "Epoch 462/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.2713e-06 - mae: 6.3926e-04 - val_loss: 7.8802e-07 - val_mae: 5.2868e-04\n",
            "Epoch 463/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.4678e-06 - mae: 6.7059e-04 - val_loss: 8.2481e-07 - val_mae: 5.3821e-04\n",
            "Epoch 464/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.0455e-06 - mae: 6.0561e-04 - val_loss: 7.8335e-07 - val_mae: 5.5163e-04\n",
            "Epoch 465/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3396e-06 - mae: 6.4685e-04 - val_loss: 7.8313e-07 - val_mae: 5.2877e-04\n",
            "Epoch 466/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.2667e-06 - mae: 6.1711e-04 - val_loss: 1.7628e-06 - val_mae: 7.3613e-04\n",
            "Epoch 467/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.1422e-06 - mae: 5.5785e-04 - val_loss: 3.4773e-06 - val_mae: 7.3357e-04\n",
            "Epoch 468/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 2.5930e-05 - mae: 0.0016 - val_loss: 1.1217e-06 - val_mae: 5.5767e-04\n",
            "Epoch 469/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.0534e-07 - mae: 5.5793e-04 - val_loss: 9.7099e-07 - val_mae: 5.3639e-04\n",
            "Epoch 470/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 6.3075e-06 - mae: 8.4831e-04 - val_loss: 0.0108 - val_mae: 0.0469\n",
            "Epoch 471/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 9.8764e-04 - mae: 0.0059 - val_loss: 9.5692e-06 - val_mae: 0.0012\n",
            "Epoch 472/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 2.0066e-06 - mae: 7.5852e-04 - val_loss: 6.7844e-07 - val_mae: 5.2017e-04\n",
            "Epoch 473/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.1395e-06 - mae: 6.0681e-04 - val_loss: 1.1488e-06 - val_mae: 5.5991e-04\n",
            "Epoch 474/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.2322e-06 - mae: 6.1590e-04 - val_loss: 7.1892e-07 - val_mae: 5.0973e-04\n",
            "Epoch 475/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.1246e-06 - mae: 6.1805e-04 - val_loss: 7.5661e-07 - val_mae: 5.1867e-04\n",
            "Epoch 476/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.1239e-06 - mae: 5.9183e-04 - val_loss: 6.5205e-07 - val_mae: 5.0486e-04\n",
            "Epoch 477/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.1610e-06 - mae: 6.0710e-04 - val_loss: 1.4903e-06 - val_mae: 6.0218e-04\n",
            "Epoch 478/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.8704e-06 - mae: 6.9455e-04 - val_loss: 6.5897e-07 - val_mae: 5.0587e-04\n",
            "Epoch 479/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.3630e-06 - mae: 6.2914e-04 - val_loss: 1.5787e-06 - val_mae: 6.1997e-04\n",
            "Epoch 480/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 9.8199e-07 - mae: 5.6238e-04 - val_loss: 2.6111e-06 - val_mae: 6.9256e-04\n",
            "Epoch 481/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.1855e-06 - mae: 5.9655e-04 - val_loss: 3.4580e-06 - val_mae: 7.7122e-04\n",
            "Epoch 482/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.7296e-06 - mae: 6.6169e-04 - val_loss: 1.3132e-06 - val_mae: 5.7219e-04\n",
            "Epoch 483/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 9.3717e-07 - mae: 5.7213e-04 - val_loss: 6.6460e-07 - val_mae: 5.2046e-04\n",
            "Epoch 484/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.2878e-06 - mae: 6.2086e-04 - val_loss: 9.7004e-07 - val_mae: 5.1468e-04\n",
            "Epoch 485/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.2828e-07 - mae: 5.5500e-04 - val_loss: 6.8334e-07 - val_mae: 5.2796e-04\n",
            "Epoch 486/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.7717e-05 - mae: 0.0012 - val_loss: 2.0379e-06 - val_mae: 7.2523e-04\n",
            "Epoch 487/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.3513e-06 - mae: 6.4821e-04 - val_loss: 1.7946e-06 - val_mae: 6.6535e-04\n",
            "Epoch 488/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 9.2308e-07 - mae: 5.8123e-04 - val_loss: 1.1764e-06 - val_mae: 5.7779e-04\n",
            "Epoch 489/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.0594e-06 - mae: 5.9200e-04 - val_loss: 7.0874e-07 - val_mae: 5.0267e-04\n",
            "Epoch 490/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.0939e-06 - mae: 5.9571e-04 - val_loss: 7.9337e-07 - val_mae: 5.1441e-04\n",
            "Epoch 491/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 1.1823e-06 - mae: 6.1412e-04 - val_loss: 6.8004e-07 - val_mae: 4.9449e-04\n",
            "Epoch 492/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 8.6585e-07 - mae: 5.4354e-04 - val_loss: 1.6307e-06 - val_mae: 5.8275e-04\n",
            "Epoch 493/600\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 8.5803e-07 - mae: 5.5297e-04 - val_loss: 6.8781e-07 - val_mae: 4.8487e-04\n",
            "Epoch 494/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 9.1046e-07 - mae: 5.5956e-04 - val_loss: 7.4715e-07 - val_mae: 4.9599e-04\n",
            "Epoch 495/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 1.1043e-06 - mae: 5.7930e-04 - val_loss: 1.9371e-06 - val_mae: 6.1585e-04\n",
            "Epoch 496/600\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 9.7977e-07 - mae: 5.5734e-04 - val_loss: 1.7054e-06 - val_mae: 6.2220e-04\n",
            "Epoch 497/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 9.2374e-07 - mae: 5.4488e-04 - val_loss: 1.3396e-06 - val_mae: 5.5848e-04\n",
            "Epoch 498/600\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 1.1074e-06 - mae: 5.5938e-04 - val_loss: 6.4895e-07 - val_mae: 4.7492e-04\n",
            "Epoch 499/600\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 1.3433e-06 - mae: 6.1348e-04 - val_loss: 9.4953e-07 - val_mae: 5.1058e-04\n",
            "Epoch 500/600\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 7.6047e-07 - mae: 5.1482e-04 - val_loss: 6.0297e-07 - val_mae: 4.6908e-04\n",
            "Epoch 501/600\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 1.1495e-06 - mae: 5.4765e-04 - val_loss: 6.0858e-07 - val_mae: 4.9886e-04\n",
            "Epoch 502/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 8.3338e-07 - mae: 5.2763e-04 - val_loss: 7.1014e-07 - val_mae: 4.9025e-04\n",
            "Epoch 503/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 1.0091e-06 - mae: 5.6132e-04 - val_loss: 9.4619e-07 - val_mae: 5.1675e-04\n",
            "Epoch 504/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 8.1197e-07 - mae: 5.3690e-04 - val_loss: 5.5181e-07 - val_mae: 4.6913e-04\n",
            "Epoch 505/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 9.8363e-07 - mae: 5.5456e-04 - val_loss: 8.4836e-07 - val_mae: 5.1871e-04\n",
            "Epoch 506/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 7.4180e-07 - mae: 5.1681e-04 - val_loss: 5.9242e-07 - val_mae: 4.9287e-04\n",
            "Epoch 507/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 8.2601e-07 - mae: 5.3349e-04 - val_loss: 1.0195e-06 - val_mae: 5.3323e-04\n",
            "Epoch 508/600\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 1.1203e-06 - mae: 5.6690e-04 - val_loss: 1.5089e-06 - val_mae: 5.8450e-04\n",
            "Epoch 509/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.0268e-06 - mae: 5.5779e-04 - val_loss: 8.3439e-07 - val_mae: 4.8946e-04\n",
            "Epoch 510/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.3177e-06 - mae: 5.6791e-04 - val_loss: 7.9522e-07 - val_mae: 4.8395e-04\n",
            "Epoch 511/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.6952e-07 - mae: 5.3474e-04 - val_loss: 1.0827e-06 - val_mae: 5.3441e-04\n",
            "Epoch 512/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.0181e-06 - mae: 5.6251e-04 - val_loss: 7.4464e-07 - val_mae: 4.7941e-04\n",
            "Epoch 513/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.3850e-07 - mae: 5.3021e-04 - val_loss: 7.7873e-07 - val_mae: 4.9131e-04\n",
            "Epoch 514/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.0138e-06 - mae: 5.5187e-04 - val_loss: 9.4388e-07 - val_mae: 5.2976e-04\n",
            "Epoch 515/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.3365e-07 - mae: 5.4656e-04 - val_loss: 1.1561e-06 - val_mae: 5.2632e-04\n",
            "Epoch 516/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.9177e-07 - mae: 5.3398e-04 - val_loss: 8.6044e-07 - val_mae: 5.0490e-04\n",
            "Epoch 517/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.9237e-07 - mae: 5.3827e-04 - val_loss: 1.2689e-06 - val_mae: 5.4549e-04\n",
            "Epoch 518/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.2925e-07 - mae: 5.3170e-04 - val_loss: 5.2734e-07 - val_mae: 4.6013e-04\n",
            "Epoch 519/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.3933e-07 - mae: 5.0944e-04 - val_loss: 1.6609e-06 - val_mae: 5.8509e-04\n",
            "Epoch 520/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 1.0790e-06 - mae: 5.6336e-04 - val_loss: 5.6401e-07 - val_mae: 4.6087e-04\n",
            "Epoch 521/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 7.8345e-07 - mae: 5.1265e-04 - val_loss: 1.5239e-06 - val_mae: 5.6894e-04\n",
            "Epoch 522/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.0366e-06 - mae: 5.5605e-04 - val_loss: 5.3961e-07 - val_mae: 4.5717e-04\n",
            "Epoch 523/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.2278e-07 - mae: 5.1994e-04 - val_loss: 1.0849e-06 - val_mae: 5.1253e-04\n",
            "Epoch 524/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.0918e-06 - mae: 5.6399e-04 - val_loss: 5.8841e-07 - val_mae: 4.5571e-04\n",
            "Epoch 525/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.5130e-07 - mae: 5.0833e-04 - val_loss: 6.7058e-07 - val_mae: 5.0918e-04\n",
            "Epoch 526/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.0489e-06 - mae: 5.5260e-04 - val_loss: 5.2504e-07 - val_mae: 4.5248e-04\n",
            "Epoch 527/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.5567e-07 - mae: 5.4069e-04 - val_loss: 6.0769e-07 - val_mae: 4.4981e-04\n",
            "Epoch 528/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.0275e-06 - mae: 5.2656e-04 - val_loss: 4.9222e-07 - val_mae: 4.4771e-04\n",
            "Epoch 529/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.1188e-06 - mae: 5.5398e-04 - val_loss: 5.4864e-07 - val_mae: 4.4371e-04\n",
            "Epoch 530/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 8.4441e-07 - mae: 5.0457e-04 - val_loss: 1.3160e-06 - val_mae: 5.3258e-04\n",
            "Epoch 531/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 1.0201e-06 - mae: 5.4809e-04 - val_loss: 5.3307e-07 - val_mae: 4.4899e-04\n",
            "Epoch 532/600\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 7.7143e-07 - mae: 5.1352e-04 - val_loss: 4.9806e-07 - val_mae: 4.5154e-04\n",
            "Epoch 533/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.7160e-07 - mae: 5.3142e-04 - val_loss: 1.3512e-06 - val_mae: 5.7231e-04\n",
            "Epoch 534/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.4067e-07 - mae: 5.3041e-04 - val_loss: 7.4855e-07 - val_mae: 4.8745e-04\n",
            "Epoch 535/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.7420e-07 - mae: 5.0828e-04 - val_loss: 1.1534e-06 - val_mae: 5.3815e-04\n",
            "Epoch 536/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.5156e-07 - mae: 5.0862e-04 - val_loss: 8.8174e-07 - val_mae: 5.0033e-04\n",
            "Epoch 537/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.0154e-07 - mae: 4.7203e-04 - val_loss: 4.9722e-07 - val_mae: 4.5167e-04\n",
            "Epoch 538/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 9.9687e-07 - mae: 5.3651e-04 - val_loss: 5.8428e-07 - val_mae: 4.4471e-04\n",
            "Epoch 539/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.6718e-07 - mae: 5.0597e-04 - val_loss: 1.1654e-06 - val_mae: 5.2668e-04\n",
            "Epoch 540/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 8.3950e-07 - mae: 5.1129e-04 - val_loss: 6.0107e-07 - val_mae: 4.4272e-04\n",
            "Epoch 541/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 8.3330e-07 - mae: 5.1535e-04 - val_loss: 4.8602e-07 - val_mae: 4.3614e-04\n",
            "Epoch 542/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 7.3401e-07 - mae: 4.6595e-04 - val_loss: 1.5557e-06 - val_mae: 5.5617e-04\n",
            "Epoch 543/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 8.3237e-07 - mae: 4.8822e-04 - val_loss: 1.0465e-06 - val_mae: 5.1797e-04\n",
            "Epoch 544/600\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 8.4293e-07 - mae: 5.1770e-04 - val_loss: 8.7922e-07 - val_mae: 4.9196e-04\n",
            "Epoch 545/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 7.9933e-07 - mae: 5.0129e-04 - val_loss: 4.8642e-07 - val_mae: 4.4659e-04\n",
            "Epoch 546/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 7.3781e-07 - mae: 5.0224e-04 - val_loss: 5.2844e-07 - val_mae: 4.3388e-04\n",
            "Epoch 547/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 7.8064e-07 - mae: 4.8603e-04 - val_loss: 4.7171e-07 - val_mae: 4.4032e-04\n",
            "Epoch 548/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 7.1960e-07 - mae: 4.8464e-04 - val_loss: 1.0309e-06 - val_mae: 5.0445e-04\n",
            "Epoch 549/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 8.0105e-07 - mae: 5.0048e-04 - val_loss: 5.1483e-07 - val_mae: 4.2524e-04\n",
            "Epoch 550/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 8.1358e-07 - mae: 4.8958e-04 - val_loss: 4.8462e-07 - val_mae: 4.4581e-04\n",
            "Epoch 551/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.9575e-07 - mae: 5.0863e-04 - val_loss: 4.5430e-07 - val_mae: 4.2948e-04\n",
            "Epoch 552/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.0396e-07 - mae: 4.6308e-04 - val_loss: 1.2275e-06 - val_mae: 5.1218e-04\n",
            "Epoch 553/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.3986e-07 - mae: 4.7044e-04 - val_loss: 4.4602e-07 - val_mae: 4.2363e-04\n",
            "Epoch 554/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 8.0221e-07 - mae: 5.0315e-04 - val_loss: 5.3805e-07 - val_mae: 4.2382e-04\n",
            "Epoch 555/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 7.5772e-07 - mae: 4.7648e-04 - val_loss: 1.2184e-06 - val_mae: 5.2953e-04\n",
            "Epoch 556/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.3084e-07 - mae: 5.0849e-04 - val_loss: 1.0267e-06 - val_mae: 5.0503e-04\n",
            "Epoch 557/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.8925e-07 - mae: 5.0111e-04 - val_loss: 4.6265e-07 - val_mae: 4.2466e-04\n",
            "Epoch 558/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.5265e-07 - mae: 4.7391e-04 - val_loss: 7.9421e-07 - val_mae: 4.5954e-04\n",
            "Epoch 559/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 7.3289e-07 - mae: 4.8301e-04 - val_loss: 6.3867e-07 - val_mae: 4.4307e-04\n",
            "Epoch 560/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.1548e-07 - mae: 4.6042e-04 - val_loss: 4.3739e-07 - val_mae: 4.2109e-04\n",
            "Epoch 561/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.2619e-07 - mae: 4.9702e-04 - val_loss: 4.4645e-07 - val_mae: 4.2145e-04\n",
            "Epoch 562/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.9132e-07 - mae: 4.5894e-04 - val_loss: 9.3618e-07 - val_mae: 4.8513e-04\n",
            "Epoch 563/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 8.2939e-07 - mae: 4.9702e-04 - val_loss: 5.8603e-07 - val_mae: 4.3460e-04\n",
            "Epoch 564/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 7.4567e-07 - mae: 4.8700e-04 - val_loss: 6.1849e-07 - val_mae: 4.3474e-04\n",
            "Epoch 565/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 6.7614e-07 - mae: 4.7288e-04 - val_loss: 8.5731e-07 - val_mae: 4.6943e-04\n",
            "Epoch 566/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 6.4849e-07 - mae: 4.6653e-04 - val_loss: 1.0572e-06 - val_mae: 4.9108e-04\n",
            "Epoch 567/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 7.2561e-07 - mae: 4.6496e-04 - val_loss: 8.3247e-07 - val_mae: 4.5126e-04\n",
            "Epoch 568/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 7.5690e-07 - mae: 4.6881e-04 - val_loss: 9.0375e-07 - val_mae: 4.5877e-04\n",
            "Epoch 569/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 5.9908e-07 - mae: 4.5080e-04 - val_loss: 1.2503e-06 - val_mae: 4.9846e-04\n",
            "Epoch 570/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 6.5168e-07 - mae: 4.5833e-04 - val_loss: 1.1512e-06 - val_mae: 4.9000e-04\n",
            "Epoch 571/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 7.5445e-07 - mae: 4.7597e-04 - val_loss: 7.2757e-07 - val_mae: 4.3550e-04\n",
            "Epoch 572/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 5.8858e-07 - mae: 4.2804e-04 - val_loss: 1.4420e-06 - val_mae: 5.3609e-04\n",
            "Epoch 573/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 5.9053e-07 - mae: 4.6502e-04 - val_loss: 4.9021e-07 - val_mae: 4.1325e-04\n",
            "Epoch 574/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.0692e-07 - mae: 4.4729e-04 - val_loss: 1.1700e-06 - val_mae: 5.1167e-04\n",
            "Epoch 575/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.0684e-07 - mae: 4.5593e-04 - val_loss: 4.2692e-07 - val_mae: 4.1588e-04\n",
            "Epoch 576/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 7.5733e-07 - mae: 4.7909e-04 - val_loss: 5.4708e-07 - val_mae: 4.1802e-04\n",
            "Epoch 577/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 6.5481e-07 - mae: 4.5453e-04 - val_loss: 4.2972e-07 - val_mae: 4.0915e-04\n",
            "Epoch 578/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.8652e-07 - mae: 4.5600e-04 - val_loss: 4.4719e-07 - val_mae: 4.0363e-04\n",
            "Epoch 579/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 5.0582e-07 - mae: 4.2351e-04 - val_loss: 1.1609e-06 - val_mae: 4.8908e-04\n",
            "Epoch 580/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.2082e-07 - mae: 4.3992e-04 - val_loss: 1.2568e-06 - val_mae: 4.9285e-04\n",
            "Epoch 581/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 9.0553e-07 - mae: 4.8025e-04 - val_loss: 7.0646e-07 - val_mae: 4.5763e-04\n",
            "Epoch 582/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.7874e-07 - mae: 4.6394e-04 - val_loss: 9.1792e-07 - val_mae: 4.7863e-04\n",
            "Epoch 583/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.6182e-07 - mae: 4.6511e-04 - val_loss: 4.3124e-07 - val_mae: 4.1078e-04\n",
            "Epoch 584/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 6.5485e-07 - mae: 4.4874e-04 - val_loss: 7.0702e-07 - val_mae: 4.5003e-04\n",
            "Epoch 585/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.0786e-07 - mae: 4.2189e-04 - val_loss: 4.3209e-07 - val_mae: 4.1988e-04\n",
            "Epoch 586/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 7.5909e-07 - mae: 4.7914e-04 - val_loss: 4.8001e-07 - val_mae: 4.0882e-04\n",
            "Epoch 587/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 6.2334e-07 - mae: 4.5330e-04 - val_loss: 6.5037e-07 - val_mae: 4.2954e-04\n",
            "Epoch 588/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 6.0863e-07 - mae: 4.4503e-04 - val_loss: 7.7618e-07 - val_mae: 4.4149e-04\n",
            "Epoch 589/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 5.8164e-07 - mae: 4.4784e-04 - val_loss: 4.0692e-07 - val_mae: 3.9588e-04\n",
            "Epoch 590/600\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 6.8964e-07 - mae: 4.6875e-04 - val_loss: 5.1082e-07 - val_mae: 4.0862e-04\n",
            "Epoch 591/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 5.5821e-07 - mae: 4.2986e-04 - val_loss: 3.9248e-07 - val_mae: 3.9712e-04\n",
            "Epoch 592/600\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 7.6458e-07 - mae: 4.7468e-04 - val_loss: 7.2880e-07 - val_mae: 4.4236e-04\n",
            "Epoch 593/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 6.9211e-07 - mae: 4.6031e-04 - val_loss: 6.6610e-07 - val_mae: 4.3870e-04\n",
            "Epoch 594/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 6.5304e-07 - mae: 4.5364e-04 - val_loss: 4.4425e-07 - val_mae: 4.0104e-04\n",
            "Epoch 595/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 6.1205e-07 - mae: 4.5149e-04 - val_loss: 5.7298e-07 - val_mae: 4.2290e-04\n",
            "Epoch 596/600\n",
            "57/57 [==============================] - 0s 8ms/step - loss: 6.0164e-07 - mae: 4.4957e-04 - val_loss: 4.9357e-07 - val_mae: 4.0004e-04\n",
            "Epoch 597/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 6.2352e-07 - mae: 4.4441e-04 - val_loss: 4.5473e-07 - val_mae: 3.9292e-04\n",
            "Epoch 598/600\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 6.1822e-07 - mae: 4.4012e-04 - val_loss: 4.3131e-07 - val_mae: 3.9339e-04\n",
            "Epoch 599/600\n",
            "57/57 [==============================] - 0s 4ms/step - loss: 6.3013e-07 - mae: 4.4760e-04 - val_loss: 4.8439e-07 - val_mae: 3.9643e-04\n",
            "Epoch 600/600\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 5.5552e-07 - mae: 4.3892e-04 - val_loss: 8.0765e-07 - val_mae: 4.4196e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversión del modelo entrenado a Tensor Flow Lite\n",
        "\n",
        "Se convierte el modela al formato TFlite. Se indica también el tamaño del modelo en bytes."
      ],
      "metadata": {
        "id": "8P_7FIJFRurn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se convierte el modelo al formato TensorFlow Lite sin cuantización\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Se salva el modelo al disco\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "  \n",
        "import os\n",
        "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "print(\"Model is %d bytes\" % basic_model_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VCtYja6T5wH",
        "outputId": "54a75e02-0248-4162-e550-b3c5d2ea4bd8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is 24744 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Codificación del modelo en un archivo header de Arduino\n",
        "\n",
        "Se convierte el modelo en un arreglo constante de bytes que contiene el modelo TFlite."
      ],
      "metadata": {
        "id": "HN_DQ8vtUQDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"const unsigned char model[] = {\" > /content/model.h\n",
        "!cat gesture_model.tflite | xxd -i      >> /content/model.h\n",
        "!echo \"};\"                              >> /content/model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\\n\")\n",
        "print(\"Open the side panel (refresh if needed).\\n\")\n",
        "print(\"Double click model.h to download the file.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzavpU7rU09-",
        "outputId": "6deb6a9e-fdcd-4015-c037-f546a4e47458"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Header file, model.h, is 152,622 bytes.\n",
            "\n",
            "Open the side panel (refresh if needed).\n",
            "\n",
            "Double click model.h to download the file.\n"
          ]
        }
      ]
    }
  ]
}